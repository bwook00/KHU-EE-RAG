vectordb:
  - name: chroma_large
    db_type: chroma
    client_type: persistent
    embedding_model: huggingface_multilingual_e5_large
    collection_name: huggingface_multilingual_e5_large
    path: ${PROJECT_DIR}/resources/chroma
    embedding_batch: 256
node_lines:
- node_line_name: retrieve_node_line
  nodes:
    - node_type: lexical_retrieval
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        speed_threshold: 10
      top_k: 10
      modules:
        - module_type: bm25
    - node_type: semantic_retrieval
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        speed_threshold: 10
      top_k: 10
      modules:
        - module_type: vectordb
          vectordb: chroma_large
    - node_type: hybrid_retrieval
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        speed_threshold: 10
      top_k: 10
      modules:
        - module_type: hybrid_rrf
          weight_range: (4,80)
        - module_type: hybrid_cc
          normalize_method: [ mm, tmm, z, dbsf ]
          weight_range: (0.0, 1.0)
          test_weight_size: 101
    - node_type: passage_augmenter
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
        speed_threshold: 5
      top_k: 5
      embedding_model: upstage
      modules:
        - module_type: pass_passage_augmenter
        - module_type: prev_next_augmenter
          mode: next
    - node_type: passage_reranker
      modules:
        - module_type: koreranker
        - module_type: upr
        - module_type: pass_reranker
      strategy:
        metrics: [ retrieval_recall, retrieval_precision, retrieval_map ]
      top_k: 3
    - node_type: passage_filter
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
        speed_threshold: 5
      modules:
        - module_type: pass_passage_filter
        - module_type: threshold_cutoff
          threshold: 0.85
        - module_type: percentile_cutoff
          percentile: 0.6
    - node_type: passage_compressor
      strategy:
        metrics: [retrieval_token_f1, retrieval_token_recall, retrieval_token_precision]
        speed_threshold: 10
      modules:
        - module_type: pass_compressor
        - module_type: tree_summarize
          llm: upstage
          model: [ solar-pro2 ]
          prompt: |
            여러 문맥 정보는 다음과 같습니다.\n
            ---------------------\n
            {context_str}\n
            ---------------------\n
            사전 지식이 아닌 여러 정보가 주어졌습니다,
            질문에 대답하세요.\n
            질문: {query_str}\n
            답변:
        - module_type: refine
          llm: upstage
          model: [ solar-pro2 ]
          prompt: |
            원래 질문은 다음과 같습니다: {query_str}
            기존 답변은 다음과 같습니다: {existing_answer}
            아래에서 기존 답변을 정제할 수 있는 기회가 있습니다.
            (필요한 경우에만) 아래에 몇 가지 맥락을 추가하여 기존 답변을 정제할 수 있습니다.
            ------------
            {context_msg}
            ------------
            새로운 문맥이 주어지면 기존 답변을 수정하여 질문에 대한 답변을 정제합니다.
            맥락이 쓸모 없다면, 기존 답변을 그대로 답변하세요.
            정제된 답변:
- node_line_name: post_retrieve_node_line
  nodes:
    - node_type: prompt_maker
      strategy:
        metrics:
          - metric_name: bleu
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: upstage
        speed_threshold: 10
        generator_modules:
          - module_type: llama_index_llm
            llm: upstage
            model: [solar-pro2]
      modules:
        - module_type: fstring
          prompt: ["경희대학교 학생들을 챗봇입니다. 오직, 주어진 학칙만을 이용하여 질문에 따라 답하시오. 모르면 모른다고 대답하시오. 최대한 보수적으로 대답하시오. 학칙: {retrieved_contents} \n\n 질문: {query} \n\n 답변:"]
